{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPo+KEP/zZPqUlJJafztAF/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TPGREcajrX6Z","executionInfo":{"status":"ok","timestamp":1747469169906,"user_tz":-180,"elapsed":16869,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}},"outputId":"f7da0cc7-5bd7-4427-9e40-d2c2c09cc79b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","folder_path = '/content/drive/MyDrive/telecom/5sem'\n","video = os.path.join(folder_path, \"person15_running_d1_uncomp.avi\")"],"metadata":{"id":"TmlGUcDXrjTa","executionInfo":{"status":"ok","timestamp":1747469169907,"user_tz":-180,"elapsed":13,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["video = []\n","for f in os.listdir(path = folder_path):\n","    if f[:6] == 'person':\n","        video.append(os.path.join(folder_path, f))"],"metadata":{"id":"w2wUgQ-osSLm","executionInfo":{"status":"ok","timestamp":1747469170561,"user_tz":-180,"elapsed":656,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"dD9sfNwvrF4C","executionInfo":{"status":"ok","timestamp":1747469170583,"user_tz":-180,"elapsed":20,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class ConvLSTMCell(nn.Module):\n","    def __init__(self, input_channels, hidden_channels, kernel_size=3):\n","        super().__init__()\n","        padding = kernel_size // 2\n","        self.input_channels = input_channels\n","        self.hidden_channels = hidden_channels\n","\n","        self.conv = nn.Conv2d(\n","            input_channels + hidden_channels,\n","            4 * hidden_channels,\n","            kernel_size,\n","            padding=padding\n","        )\n","\n","    def forward(self, x, h_prev, c_prev):\n","        combined = torch.cat([x, h_prev], dim=1)\n","        conv_output = self.conv(combined)\n","\n","        cc_i, cc_f, cc_o, cc_g = torch.chunk(conv_output, 4, dim=1)\n","        i = torch.sigmoid(cc_i)\n","        f = torch.sigmoid(cc_f)\n","        o = torch.sigmoid(cc_o)\n","        g = torch.tanh(cc_g)\n","\n","        c = f * c_prev + i * g\n","        h = o * torch.tanh(c)\n","\n","        return h, c"]},{"cell_type":"code","source":["class ConvLSTM(nn.Module):\n","    def __init__(self, input_channels=1, hidden_channels=64, kernel_size=3, pred_len=5):\n","        super().__init__()\n","        self.cell = ConvLSTMCell(input_channels, hidden_channels, kernel_size)\n","        self.conv_out = nn.Conv2d(hidden_channels, input_channels, kernel_size=1)\n","        self.pred_len = pred_len\n","\n","    def forward(self, x_seq):\n","        B, T, C, H, W = x_seq.shape\n","        h = torch.zeros(B, self.cell.hidden_channels, H, W, device=x_seq.device)\n","        c = torch.zeros_like(h)\n","\n","        for t in range(T):\n","            h, c = self.cell(x_seq[:, t], h, c)\n","\n","        outputs = []\n","        x_in = x_seq[:, -1]\n","        for _ in range(self.pred_len):\n","            h, c = self.cell(x_in, h, c)\n","            x_in = self.conv_out(h)\n","            outputs.append(x_in)\n","\n","        return torch.stack(outputs, dim=1)\n"],"metadata":{"id":"MT7652rvrQO6","executionInfo":{"status":"ok","timestamp":1747469170593,"user_tz":-180,"elapsed":11,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","def check_info_about_video(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","\n","    if not cap.isOpened():\n","        print(\"Ошибка: не удалось открыть видео.\")\n","    else:\n","        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","        fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","\n","        ret, frame = cap.read()\n","        if ret:\n","            channels = frame.shape[2] if len(frame.shape) == 3 else 1\n","\n","            print(f'Кадров: {frame_count}')\n","            print(f'Размер кадра: {width}x{height}')\n","            print(f'Число каналов: {channels}')\n","            print(f'FPS: {fps}')\n","        else:\n","            print(\"Не удалось считать первый кадр.\")\n","\n","    cap.release()\n","for _ in video:\n","    check_info_about_video(_)\n","    print('\\n\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FldLAAGsJS_","executionInfo":{"status":"ok","timestamp":1747469175050,"user_tz":-180,"elapsed":4454,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}},"outputId":"948dc7b8-b1aa-4d52-adf4-7c89ffbc45de"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Кадров: 432\n","Размер кадра: 160x120\n","Число каналов: 3\n","FPS: 25.0\n","\n","\n","\n","Кадров: 160\n","Размер кадра: 160x120\n","Число каналов: 3\n","FPS: 25.0\n","\n","\n","\n","Кадров: 206\n","Размер кадра: 160x120\n","Число каналов: 3\n","FPS: 25.0\n","\n","\n","\n","Кадров: 581\n","Размер кадра: 160x120\n","Число каналов: 3\n","FPS: 25.0\n","\n","\n","\n","Кадров: 312\n","Размер кадра: 160x120\n","Число каналов: 3\n","FPS: 25.0\n","\n","\n","\n","Кадров: 408\n","Размер кадра: 160x120\n","Число каналов: 3\n","FPS: 25.0\n","\n","\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def load_video_tensor(path):\n","    cap = cv2.VideoCapture(path)\n","    frames = []\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.resize(frame, (160, 120))\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        frame = frame.astype(np.float32) / 255.0\n","        frames.append(frame)\n","\n","    cap.release()\n","\n","\n","    video_np = np.stack(frames)\n","    video_np = np.transpose(video_np, (0, 3, 1, 2))\n","    video_tensor = torch.from_numpy(video_np)\n","\n","    return video_tensor\n"],"metadata":{"id":"C5LqkdEUtcaG","executionInfo":{"status":"ok","timestamp":1747469175070,"user_tz":-180,"elapsed":8,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["video_tensor = load_video_tensor(video[0])\n","print(video_tensor.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-956S1MtjMs","executionInfo":{"status":"ok","timestamp":1747469175403,"user_tz":-180,"elapsed":331,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}},"outputId":"8a9f1093-114a-4f97-dcf4-9e29da277b76"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([432, 3, 120, 160])\n"]}]},{"cell_type":"code","source":["import cv2\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset\n","\n","class VideoFrameDataset(Dataset):\n","    def __init__(self, video_paths, seq_len=10, pred_len=5):\n","        self.samples = []\n","        self.seq_len = seq_len\n","        self.pred_len = pred_len\n","\n","        for path in video_paths:\n","            video = self.load_video_tensor(path)\n","            T = video.shape[0]\n","            for i in range(T - seq_len - pred_len + 1):\n","                x = video[i:i + seq_len]\n","                y = video[i + seq_len : i + seq_len + pred_len]\n","                self.samples.append((x, y))\n","\n","    def load_video_tensor(self, path):\n","        cap = cv2.VideoCapture(path)\n","        frames = []\n","\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = cv2.resize(frame, (160, 120))\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            frame = frame.astype(np.float32) / 255.0\n","            frames.append(frame)\n","\n","        cap.release()\n","        video_np = np.stack(frames)\n","        video_np = np.transpose(video_np, (0, 3, 1, 2))\n","        return torch.from_numpy(video_np)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        x_seq, y_seq = self.samples[idx]\n","        return x_seq, y_seq\n","\n"],"metadata":{"id":"7UlcVS_UuOih","executionInfo":{"status":"ok","timestamp":1747469175422,"user_tz":-180,"elapsed":8,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","dataset = VideoFrameDataset(video, seq_len=10)\n","dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"],"metadata":{"id":"Dr4_dS3ruSWC","executionInfo":{"status":"ok","timestamp":1747469178354,"user_tz":-180,"elapsed":2808,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML"],"metadata":{"id":"lyVKAgXsuuBd","executionInfo":{"status":"ok","timestamp":1747469178368,"user_tz":-180,"elapsed":25,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def show_sequence_from_loader(model, dataloader, device, seq_index=0):\n","    model.eval()\n","    with torch.no_grad():\n","        x_seq_batch, target_batch = next(iter(dataloader))\n","        x_seq = x_seq_batch[seq_index].unsqueeze(0).to(device)\n","        target_seq = target_batch[seq_index].cpu()\n","\n","        pred_seq = model(x_seq)[0].cpu()\n","\n","        frames = x_seq[0].cpu().permute(0, 2, 3, 1).numpy()\n","\n","        fig, ax = plt.subplots()\n","        im = ax.imshow(frames[0], cmap='gray' if frames.shape[-1] == 1 else None)\n","        ax.set_title(\"Входные кадры\")\n","        plt.axis('off')\n","\n","        def update(i):\n","            im.set_array(frames[i])\n","            ax.set_title(f\"Кадр {i+1}\")\n","            return [im]\n","\n","        ani = animation.FuncAnimation(fig, update, frames=len(frames), interval=400, blit=True)\n","        plt.close(fig)\n","        display(HTML(ani.to_jshtml()))\n","\n","        fig, axs = plt.subplots(2, 5, figsize=(15, 5))\n","        for i in range(5):\n","            axs[0, i].imshow(pred_seq[i].permute(1, 2, 0).squeeze(), cmap='gray')\n","            axs[0, i].set_title(f\"🔮 Pred {i+1}\")\n","            axs[0, i].axis('off')\n","\n","            axs[1, i].imshow(target_seq[i].permute(1, 2, 0).squeeze(), cmap='gray')\n","            axs\n"],"metadata":{"id":"qtKNwoSAuvYm","executionInfo":{"status":"ok","timestamp":1747469178387,"user_tz":-180,"elapsed":18,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm"],"metadata":{"id":"CuCsio6wyC6Q","executionInfo":{"status":"ok","timestamp":1747469178403,"user_tz":-180,"elapsed":14,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML, display\n","def visualize_fixed_sample(model, x_fixed, target_fixed, epoch):\n","    model.eval()\n","    with torch.no_grad():\n","        pred_seq = model(x_fixed)[0].cpu()\n","        input_frames = x_fixed[0].cpu().permute(0, 2, 3, 1).numpy()\n","\n","        fig, ax = plt.subplots()\n","        im = ax.imshow(input_frames[0], cmap='gray' if input_frames.shape[-1] == 1 else None)\n","        ax.set_title(\"Входные кадры\")\n","        plt.axis('off')\n","\n","        def update(i):\n","            im.set_array(input_frames[i])\n","            ax.set_title(f\"Кадр {i+1}\")\n","            return [im]\n","\n","        ani = animation.FuncAnimation(fig, update, frames=len(input_frames), interval=400, blit=True)\n","        plt.close(fig)\n","        print(f\"\\n Предсказание после эпохи {epoch}:\")\n","        display(HTML(ani.to_jshtml()))\n","\n","        fig, axs = plt.subplots(2, 5, figsize=(15, 5))\n","\n","        for i in range(5):\n","            pred_frame = pred_seq[i].permute(1, 2, 0).squeeze()\n","            true_frame = target_fixed[i].permute(1, 2, 0).squeeze()\n","\n","            axs[0, i].imshow(pred_frame, cmap='gray' if pred_frame.ndim == 2 else None)\n","            axs[0, i].set_title(f\" Pred {i+1}\")\n","            axs[0, i].axis('off')\n","\n","            axs[1, i].imshow(true_frame, cmap='gray' if true_frame.ndim == 2 else None)\n","            axs[1, i].set_title(f\" True {i+1}\")\n","            axs[1, i].axis('off')\n","\n","        plt.tight_layout()\n","        plt.show()\n"],"metadata":{"id":"O8DKC72zyzn_","executionInfo":{"status":"ok","timestamp":1747469178406,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML, display\n","\n","\n","def train_convlstm(model, dataloader, num_epochs=10, lr=1e-3):\n","    import torch\n","    import torch.nn as nn\n","    import torch.optim as optim\n","    import matplotlib.pyplot as plt\n","    import matplotlib.animation as animation\n","    from IPython.display import HTML, display\n","    from tqdm import tqdm\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = model.to(device)\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    x_fixed_batch, target_fixed_batch = next(iter(dataloader))\n","    x_fixed = x_fixed_batch[0].unsqueeze(0).to(device)\n","    target_fixed = target_fixed_batch[0].cpu()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for x_seq, target_seq in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n","            x_seq = x_seq.to(device)\n","            target_seq = target_seq.to(device)\n","\n","            optimizer.zero_grad()\n","            output = model(x_seq)\n","            loss = criterion(output, target_seq)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        avg_loss = running_loss / len(dataloader)\n","        print(f\"\\n Epoch {epoch+1}/{num_epochs} — Loss: {avg_loss:.6f}\")\n","\n","        visualize_fixed_sample(model, x_fixed, target_fixed, epoch+1)\n"],"metadata":{"id":"pDaUOT8ByE_J","executionInfo":{"status":"ok","timestamp":1747469178558,"user_tz":-180,"elapsed":144,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["num_epochs = 50\n","model = ConvLSTM(input_channels=3, hidden_channels=64)\n","train_convlstm(model, dataloader, num_epochs=10, lr=1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qsJfm5HMKVl-FM2uYiWK4Gm5ATOlCSWI"},"id":"cyg65hlcyH1G","executionInfo":{"status":"ok","timestamp":1747466510557,"user_tz":-180,"elapsed":1803994,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}},"outputId":"bd355e17-e437-46cc-9a08-412d7156100e"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'convlstm_model.pth')"],"metadata":{"id":"kK8yqXYByKJ2","executionInfo":{"status":"ok","timestamp":1747466510693,"user_tz":-180,"elapsed":8,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# PredRNN"],"metadata":{"id":"X7f6nRw3RZdr"}},{"cell_type":"code","source":["class ST_LSTM_Cell(nn.Module):\n","    def __init__(self, in_channels, hidden_channels, kernel_size, bias=True):\n","        super().__init__()\n","        padding = kernel_size // 2\n","        self.conv_x = nn.Conv2d(in_channels, hidden_channels * 7, kernel_size, padding=padding, bias=bias)\n","        self.conv_h = nn.Conv2d(hidden_channels, hidden_channels * 4, kernel_size, padding=padding, bias=bias)\n","        self.conv_m = nn.Conv2d(hidden_channels, hidden_channels * 3, kernel_size, padding=padding, bias=bias)\n","        self.conv_o = nn.Conv2d(hidden_channels * 2, hidden_channels, kernel_size, padding=padding, bias=bias)\n","        self.conv_last = nn.Conv2d(hidden_channels * 2, hidden_channels, 1, padding=0, bias=bias)\n","\n","    def forward(self, x, h, c, m):\n","        x_concat = self.conv_x(x)\n","        h_concat = self.conv_h(h)\n","        m_concat = self.conv_m(m)\n","\n","        i_x, f_x, g_x, i_mx, f_mx, g_mx, o_x = torch.chunk(x_concat, 7, dim=1)\n","        i_h, f_h, g_h, o_h = torch.chunk(h_concat, 4, dim=1)\n","        i_m, f_m, g_m = torch.chunk(m_concat, 3, dim=1)\n","\n","        i = torch.sigmoid(i_x + i_h)\n","        f = torch.sigmoid(f_x + f_h)\n","        g = torch.tanh(g_x + g_h)\n","        c_new = f * c + i * g\n","\n","        i_m = torch.sigmoid(i_mx + i_m)\n","        f_m = torch.sigmoid(f_mx + f_m)\n","        g_m = torch.tanh(g_mx + g_m)\n","        m_new = f_m * m + i_m * g_m\n","\n","        mem = torch.cat([c_new, m_new], dim=1)\n","        o = torch.sigmoid(o_x + o_h + self.conv_o(mem))\n","        h_new = o * torch.tanh(self.conv_last(mem))\n","\n","        return h_new, c_new, m_new\n"],"metadata":{"id":"6AbmuVMeRY7S","executionInfo":{"status":"ok","timestamp":1747469184201,"user_tz":-180,"elapsed":7,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class PredRNN(nn.Module):\n","    def __init__(self, input_channels=1, hidden_channels=64, kernel_size=5, num_layers=4, pred_len=5):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.pred_len = pred_len\n","        self.hidden_channels = hidden_channels\n","\n","        self.cells = nn.ModuleList([\n","            ST_LSTM_Cell(input_channels if i == 0 else hidden_channels, hidden_channels, kernel_size)\n","            for i in range(num_layers)\n","        ])\n","\n","        self.conv_out = nn.Conv2d(hidden_channels, input_channels, kernel_size=1)\n","\n","    def forward(self, x):  # x: [B, T, C, H, W]\n","        B, T, C, H, W = x.shape\n","        h = [torch.zeros(B, self.hidden_channels, H, W, device=x.device) for _ in range(self.num_layers)]\n","        c = [torch.zeros_like(h[0]) for _ in range(self.num_layers)]\n","        m = torch.zeros_like(h[0])\n","\n","        outputs = []\n","\n","        for t in range(T + self.pred_len):\n","            x_in = x[:, t] if t < T else outputs[-1]\n","\n","            for i, cell in enumerate(self.cells):\n","                h[i], c[i], m = cell(x_in, h[i], c[i], m)\n","                x_in = h[i]\n","\n","            outputs.append(self.conv_out(x_in))\n","\n","        return torch.stack(outputs[T:], dim=1)  # [B, pred_len, C, H, W]\n"],"metadata":{"id":"NSwEeFpnRcuq","executionInfo":{"status":"ok","timestamp":1747469186025,"user_tz":-180,"elapsed":3,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["num_epochs = 50\n","model = PredRNN(input_channels=3, hidden_channels=64, pred_len=5)\n","train_convlstm(model, dataloader, num_epochs=10, lr=1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"9cnpC8lRReVi","executionInfo":{"status":"error","timestamp":1747469244845,"user_tz":-180,"elapsed":4279,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"}},"outputId":"fff7970c-be02-4d76-b44a-3221d2317784"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10:   0%|          | 0/252 [00:04<?, ?it/s]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 24.12 MiB is free. Process 5649 has 14.71 GiB memory in use. Of the allocated memory 14.53 GiB is allocated by PyTorch, and 70.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-9499666e16ab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_convlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-1da0cee31ad8>\u001b[0m in \u001b[0;36mtrain_convlstm\u001b[0;34m(model, dataloader, num_epochs, lr)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-60f5fba0df88>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-5f6085516830>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, c, m)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mi_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mf_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mg_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mm_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi_m\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg_m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 24.12 MiB is free. Process 5649 has 14.71 GiB memory in use. Of the allocated memory 14.53 GiB is allocated by PyTorch, and 70.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]}]}